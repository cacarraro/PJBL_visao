{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bVMMm_DFJwC"
      },
      "source": [
        "Integrantes\n",
        "   - Amanda Lima\n",
        "   - Camila Carraro\n",
        "   - Dylan Ricardo\n",
        "   - Matheus Zanellato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DxY8OiJU8Pk"
      },
      "source": [
        "# 1. Materiais e Metodos\n",
        "\n",
        "*   Base e pré-processamento\n",
        "*   Descritores de Características\n",
        "*   Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEmw0MVfFOP-"
      },
      "source": [
        "## Importando as bibliotecas e carregando a base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qaTs250NAYPd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "import skimage.feature as feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkTJtJevFR_L"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/Amandals/ComputerVision/blob/development/basesimpsons.zip?raw=true -O dataset.zip \n",
        "\n",
        "!wget https://github.com/Amandals/ComputerVision/blob/development/Teste.zip?raw=true -O teste.zip \n",
        "!wget https://github.com/Amandals/ComputerVision/blob/development/Treino.zip?raw=true -O treino.zip \n",
        "\n",
        "!unzip -o dataset.zip\n",
        "!unzip -o teste.zip -d Teste\n",
        "!unzip -o Treino.zip -d Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egbi2cIQRngD"
      },
      "outputs": [],
      "source": [
        "train_list = glob.glob('/content/Treino/*.bmp')\n",
        "print(train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvJSZVG_R1HJ"
      },
      "outputs": [],
      "source": [
        "test_list = glob.glob('/content/Teste/*.bmp')\n",
        "print(test_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_labels(data_list):\n",
        "  result = []\n",
        "  for name in data_list:\n",
        "    if name.find('bart') != -1:\n",
        "      result.append(0)\n",
        "    elif name.find('homer') != -1:\n",
        "      result.append(1)\n",
        "    elif name.find('lisa') != -1:\n",
        "      result.append(2)\n",
        "    elif name.find('marge') != -1:\n",
        "      result.append(3)\n",
        "    elif name.find('maggie') != -1:\n",
        "      result.append(4)\n",
        "    elif name.find('family') != -1:\n",
        "      result.append(5)\n",
        "  return result"
      ],
      "metadata": {
        "id": "NmgdHipkRE5s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = generate_labels(train_list)\n",
        "test_labels = generate_labels(test_list)"
      ],
      "metadata": {
        "id": "QdA7Cpt2S_AW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ytRbQ2brLGdu"
      },
      "outputs": [],
      "source": [
        "#Auxiliary Function to plot side by side\n",
        "def plot_sidebyside(img_list,titles,colormap=None,figsize=(12,6)):\n",
        "  n = len(img_list)\n",
        "  figure, axis = plt.subplots(1, n, figsize=figsize)\n",
        "\n",
        "  for i in range(n):\n",
        "    axis[i].imshow(img_list[i], cmap=colormap)\n",
        "    axis[i].set_title(titles[i])\n",
        "    axis[i].axis('off')\n",
        "  # Combine all the operations and display\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXAbQtcrZL6b"
      },
      "source": [
        "## Pre-Processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyrRmH14ZRGh"
      },
      "source": [
        "### Tamanho\n",
        "\n",
        "Normalizacao de tamanhos, foram definidos diferentes \"ranges\" de tamanhos para aumentar ou diminuir as imagens. Esses ranges preservam detalhes das imagens por evitar reducoes ou aumentos muito drasticos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Aa--Jv4jhEoQ"
      },
      "outputs": [],
      "source": [
        "def resize_data(im_list):\n",
        "  result_list = []\n",
        "  for im_name in im_list:\n",
        "    im = cv2.imread(im_name)\n",
        "    s = im.shape\n",
        "\n",
        "    objective = 350\n",
        "    if s[0] < 150:\n",
        "      percent = s[0]/objective + 1\n",
        "      new_height = int(s[0] + (s[0] * percent))\n",
        "      new_width = int(s[1] + (s[1] * percent))\n",
        "      im = cv2.resize(im, (new_width, new_height))\n",
        " \n",
        "    elif s[0] >= 150 and s[0] <= 250:\n",
        "      percent = s[0]/objective\n",
        "      new_height = int(s[0] + (s[0] * percent))\n",
        "      new_width = int(s[1] + (s[1] * percent))\n",
        "      im = cv2.resize(im, (new_width, new_height))\n",
        "    \n",
        "    elif s[0] > 450 and s[0] <= 530:\n",
        "      percent = objective/s[0] - 0.3\n",
        "      new_height = int(s[0] - (s[0] * percent))\n",
        "      new_width = int(s[1] - (s[1] * percent))\n",
        "      im = cv2.resize(im, (new_width, new_height))\n",
        "\n",
        "    elif s[0] > 530 and s[0] <= 650:\n",
        "      percent = objective/s[0] - 0.2\n",
        "      new_height = int(s[0] - (s[0] * percent))\n",
        "      new_width = int(s[1] - (s[1] * percent))\n",
        "      im = cv2.resize(im, (new_width, new_height))\n",
        "\n",
        "    elif s[0] > 650:\n",
        "      percent = objective/s[0] + 0.1\n",
        "      new_height = int(s[0] - (s[0] * percent))\n",
        "      new_width = int(s[1] - (s[1] * percent))\n",
        "      im = cv2.resize(im, (new_width, new_height))\n",
        "\n",
        "    result_list.append(im)\n",
        "  return result_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U4qiwax4h3-4"
      },
      "outputs": [],
      "source": [
        "train_resized = resize_data(train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VzpsDYdMiHfD"
      },
      "outputs": [],
      "source": [
        "test_resized = resize_data(test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3W4Z7XrnZef5"
      },
      "outputs": [],
      "source": [
        "# for im in train_resized:\n",
        "#   cv2_imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDNsip7EZUxt"
      },
      "source": [
        "### Cor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XukURrWlQLZ"
      },
      "outputs": [],
      "source": [
        "for im in train_resized:\n",
        "  cv2_imshow(im)\n",
        "  # Plot dos canais de cor\n",
        "  ch_b = im[:,:,0]\n",
        "  ch_g = im[:,:,1]\n",
        "  ch_r = im[:,:,2]\n",
        "\n",
        "  plot_sidebyside([ch_b,ch_g,ch_r],[\"Blue Channel\", \"Green Channel\", \"Red Channel\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmozTsTLib8_"
      },
      "outputs": [],
      "source": [
        "for im in train_resized:\n",
        "  # Plot da imagem original\n",
        "  cv2_imshow(im)\n",
        "  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # plt.title(\"HSV\")\n",
        "  # plt.imshow(hsv,cmap='hsv')\n",
        "  # plt.show()\n",
        "\n",
        "  H = hsv[:,:,0]\n",
        "  S = hsv[:,:,1]\n",
        "  V = hsv[:,:,2]\n",
        "  h_s_v = [H, S, V]\n",
        "  # plot_sidebyside([im,H,S,V],[\"Original\", \"Hue Channel\",\"Saturaturation Channel\",\"Value Channel\"])\n",
        "  \n",
        "  val = 200\n",
        "  for i in h_s_v:\n",
        "    _, thresh = cv2.threshold(i, val, 255, cv2.THRESH_BINARY_INV)\n",
        "    plt.title(\"Thresholding Hue Channel: \" + str(val))\n",
        "    plt.imshow(thresh, cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apos a analise dos campos de cor e hsv podemos notar que o campo \"value\" eh capaz de ressaltar as caracteristicas dos cabelos, olhos e corpos dos personagens, parece um bom caminho a explorar, apesar de isso nao considerar as cores marcantes de cada personagem. A escolha de relevar as cores aqui pode ser prejudicial na extracao das features, caso aconteca testes com as cores tambem serao feitos"
      ],
      "metadata": {
        "id": "sGUov0PxopV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explorando threshold\n",
        "agora eh necessario definir o melhor threshold para o canal \"Value\" "
      ],
      "metadata": {
        "id": "tEwha7oipXTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for im in train_resized:\n",
        "  # cv2_imshow(im)\n",
        "  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  V = hsv[:,:,2]\n",
        "\n",
        "  vals = [200, 220, 230, 240, 250, 252, 253, 254]\n",
        "  thresh_list = [im]\n",
        "  for v in vals:\n",
        "    _, thresh = cv2.threshold(V, v, 255, cv2.THRESH_BINARY_INV)\n",
        "    thresh_list.append(thresh)\n",
        "\n",
        "  plot_sidebyside(thresh_list, [\"Original\", \"TVC: 200\", \"TVC: 220\", \"TVC: 230\", \"TVC: 240\", \"TVC: 250\", \"TVC: 252\", \"TVC: 253\", \"TVC: 254\"], colormap='gray')"
      ],
      "metadata": {
        "id": "SN8AF3dGpfM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "um threshold de 230 parece separar os componentes mais importantes dos personagens"
      ],
      "metadata": {
        "id": "WUIB7Dnzttx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_data(im_list):\n",
        "  result_list = []\n",
        "  for im in im_list:\n",
        "    V = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)[:,:,2]\n",
        "    _, thresh = cv2.threshold(V, 230, 255, cv2.THRESH_BINARY_INV)\n",
        "    result_list.append(thresh)\n",
        "  return result_list"
      ],
      "metadata": {
        "id": "kXHtaKAct3Ig"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_thresh = threshold_data(train_resized)\n",
        "test_val_thresh = threshold_data(test_resized) "
      ],
      "metadata": {
        "id": "mvZuaHJGu6eF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for im in train_val_thresh:\n",
        "#   cv2_imshow(im)"
      ],
      "metadata": {
        "id": "O_w-TgeAvQx0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descritores \"Edge descriptors\""
      ],
      "metadata": {
        "id": "8Inz3fRw7-dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_edges(data, algorithm='canny'):\n",
        "  features = []\n",
        "\n",
        "  for img in data:\n",
        "    #Evaluate smooth on fashion mnist data\n",
        "    #img = cv2.GaussianBlur(img,(5,5),0)\n",
        "    #_,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
        "\n",
        "    if algorithm=='canny':\n",
        "      edges = cv2.Canny(img, 100, 200)      \n",
        "    \n",
        "    elif algorithm=='sobel':\n",
        "      edges = cv2.Sobel(img, cv2.CV_64F, 1, 1)\n",
        "      #Back to UINT8\n",
        "      edges = cv2.convertScaleAbs(edges) \n",
        "\n",
        "    elif algorithm=='laplace':\n",
        "      edges = cv2.Laplacian(img, cv2.CV_64F)\n",
        "      #Back to UINT8\n",
        "      edges = cv2.convertScaleAbs(edges)\n",
        "    \n",
        "    features.append(edges)\n",
        "\n",
        "  return np.array(features)\n",
        "\n",
        "train_feat_canny = extract_edges(train_val_thresh, 'canny')\n",
        "test_feat_canny = extract_edges(test_val_thresh, 'canny')\n",
        "\n",
        "train_feat_sobel = extract_edges(train_val_thresh, 'sobel')\n",
        "test_feat_sobel = extract_edges(test_val_thresh, 'sobel')\n",
        "\n",
        "train_feat_laplace = extract_edges(train_val_thresh, 'laplace')\n",
        "test_feat_laplace = extract_edges(test_val_thresh, 'laplace')\n",
        "\n",
        "for canny,sobel,laplace,img in zip(train_feat_canny, train_feat_sobel, train_feat_laplace, train_val_thresh): \n",
        "  plot_sidebyside([img, canny, sobel, laplace],['img', 'canny', 'sobel', 'laplace'], 'gray', figsize=(10,6))"
      ],
      "metadata": {
        "id": "a4p7fO8-_xXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dos descritores analisados acima o que destaca as caracteristicas mais importantes na maioria dos casos eh o que usa o algoritmo de laplace"
      ],
      "metadata": {
        "id": "eI4J3oD4CoYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descritores \"Shape descriptors\""
      ],
      "metadata": {
        "id": "sm4AVTxJCUFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HU"
      ],
      "metadata": {
        "id": "8UvXj0jJEICv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HuMoments:\n",
        "  def describe(self,im,threshold=128):\n",
        "\n",
        "    if len(im.shape) > 2 and im.shape[2] == 3:\n",
        "      im = cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "\n",
        "    _,threshold = cv2.threshold(im, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate Moments \n",
        "    moments = cv2.moments(threshold) \n",
        "    # Calculate Hu Moments \n",
        "    huMoments = cv2.HuMoments(moments)\n",
        "\n",
        "    # Log scale hu moments \n",
        "    for i in range(0,len(huMoments)):\n",
        "      if huMoments[i] != 0:        \n",
        "        huMoments[i] = -1* math.copysign(1.0, huMoments[i]) * math.log10(abs(huMoments[i]))\n",
        "\n",
        "    #There is resulting image for HuMoments\n",
        "    return huMoments.reshape(huMoments.shape[0]), threshold"
      ],
      "metadata": {
        "id": "3lvdUorED1Xo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def humoments_data(data_list):\n",
        "  hum = HuMoments()\n",
        "  result_img = []\n",
        "  result_feat = []\n",
        "\n",
        "  for im in data_list:\n",
        "    feat, res_img = hum.describe(im)\n",
        "    result_feat.append(feat)\n",
        "    result_img.append(res_img)\n",
        "\n",
        "  result_feat = np.reshape(result_feat, (len(data_list), -1))\n",
        "  return result_img, result_feat"
      ],
      "metadata": {
        "id": "15RVhN50X0en"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HOG"
      ],
      "metadata": {
        "id": "qmYi09NIEKgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HOG:\n",
        "  def describe(self,im,pixels_per_cell=(8, 8),cells_per_block=(2, 2)):\n",
        "    if len(im.shape) > 2 and im.shape[2] == 3:\n",
        "      im = cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    im = cv2.resize(im,(64,128))\n",
        "\n",
        "    fd, hog_image = feature.hog(im, orientations=9, pixels_per_cell=pixels_per_cell,\n",
        "                \tcells_per_block=(2, 2),visualize=True)\n",
        "    return fd,hog_image"
      ],
      "metadata": {
        "id": "nA6t7eqsEOGM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hog_data(data_list):\n",
        "  hog = HOG()\n",
        "  result_img = []\n",
        "  result_feat = []\n",
        "\n",
        "  for im in data_list:\n",
        "    feat, res_img = hog.describe(im)\n",
        "    result_feat.append(feat)\n",
        "    result_img.append(res_img)\n",
        "\n",
        "  result_feat = np.reshape(result_feat, (len(data_list), -1))\n",
        "  return result_img, result_feat"
      ],
      "metadata": {
        "id": "x3CbAluqZtDg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests\n",
        "\n",
        "A partir do descritor com laplce decidimos usar as duas estrategias abaixo para classificar com KNN e SVM, portanto sao gerados as listas com as imagens e as features tanto para HUM quanto para HOG."
      ],
      "metadata": {
        "id": "ssfox8QoZmTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hum = HuMoments()\n",
        "for im in train_feat_laplace:\n",
        "  _, res_img = hum.describe(im)\n",
        "    \n",
        "  plot_sidebyside([im, res_img], [\"Input\", \"Hu Moments\"], colormap='gray')"
      ],
      "metadata": {
        "id": "mg21mAwIIP6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_laplace_hum, train_features_hum = humoments_data(train_feat_laplace)\n",
        "test_laplace_hum, test_features_hum = humoments_data(test_feat_laplace)"
      ],
      "metadata": {
        "id": "sn0iKYf4T4_4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_laplace_HOG = []\n",
        "hog = HOG()\n",
        "for im in train_feat_laplace:\n",
        "  _, res_img = hog.describe(im)\n",
        "    \n",
        "  plot_sidebyside([im, res_img], [\"Input\", \"HOG\"], colormap='gray')"
      ],
      "metadata": {
        "id": "iKha1Tpe_yiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_laplace_hog, train_features_hog = hog_data(train_feat_laplace)\n",
        "test_laplace_hog, test_features_hog = hog_data(test_feat_laplace)"
      ],
      "metadata": {
        "id": "-8G4RaaBaC9z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSGVE4VtVZ2s"
      },
      "source": [
        "# 2. Experimentos: Detalhamento do treinamento dos modelos escolhidos e exposição dos resultados\n",
        "\n",
        "* Treinamento dos modelos\n",
        "* Matriz de Confusão e Taxas de Acerto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {'bart':0, 'homer':1, 'lisa':2, 'marge': 3, 'maggie' : 4, 'family':5} "
      ],
      "metadata": {
        "id": "BwiThuw5QKhJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "muenUnfxVgg3"
      },
      "outputs": [],
      "source": [
        "def performance_evaluation(x_test, y_test, predictions, info_message):\n",
        "  \n",
        "  print(f\"Evaluation of \", info_message)\n",
        "  print(f\"{metrics.classification_report(y_test, predicted)}\\n\")\n",
        "  disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
        "  disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
      ],
      "metadata": {
        "id": "5zKUwVRbd5I1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "v1TLByVWa30i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN HUM"
      ],
      "metadata": {
        "id": "r8HxhCr8a5Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hum\n",
        "test = test_features_hum\n",
        "print('Processing - KNN - Hu Moments')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=8)\n",
        "knn.fit(train, train_labels)\n",
        "predicted = knn.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'Hu Moments')"
      ],
      "metadata": {
        "id": "mf6hiYkMF_v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN HOG"
      ],
      "metadata": {
        "id": "Rwk50hIta6sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hog\n",
        "test = test_features_hog\n",
        "print('Processing - HOG')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "knn.fit(train, train_labels)\n",
        "predicted = knn.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'HOG')"
      ],
      "metadata": {
        "id": "2X1x0QD1a9wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "nS8BWsgdbWLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM HUM"
      ],
      "metadata": {
        "id": "lylUHziGbXna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hum\n",
        "test = test_features_hum\n",
        "print('Processing - SVM - Hu Moments')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(train, train_labels)\n",
        "predicted = svm.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'SVM - Hu Moments')"
      ],
      "metadata": {
        "id": "sPcEklc7bZ1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM HOG"
      ],
      "metadata": {
        "id": "T3ZKN3-cbaCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hog\n",
        "test = test_features_hog\n",
        "print('Processing - SVM - HOG')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(train, train_labels)\n",
        "predicted = svm.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'SVM - HOG')"
      ],
      "metadata": {
        "id": "6adlY69gbbfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RF"
      ],
      "metadata": {
        "id": "_nSV9JPrfCTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF HUM"
      ],
      "metadata": {
        "id": "C_AmZpy6fDYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hum\n",
        "test = test_features_hum\n",
        "print('Processing - Random Forest - Hu Moments')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=340, random_state=1, min_samples_split=10)\n",
        "rf.fit(train, train_labels)\n",
        "predicted = rf.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'Random Forest - Hu Moments')"
      ],
      "metadata": {
        "id": "xzmB42e3fG73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF HOG"
      ],
      "metadata": {
        "id": "I6TOTpb6fFWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hog\n",
        "test = test_features_hog\n",
        "print('Processing - Random Forest - HOG')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=250, random_state=1, min_samples_split=5)\n",
        "rf.fit(train, train_labels)\n",
        "predicted = rf.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'Random Forest - HOG')"
      ],
      "metadata": {
        "id": "j84ys7otfHg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADA BOOST"
      ],
      "metadata": {
        "id": "sEXrNWJPhVbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADA HUM"
      ],
      "metadata": {
        "id": "Qt696hjchnf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hum\n",
        "test = test_features_hum\n",
        "print('Processing - Ada Boost - Hu Moments')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "classif = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
        "ada = AdaBoostClassifier(base_estimator=classif)\n",
        "ada.fit(train, train_labels)\n",
        "predicted = ada.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'Ada Boost - Hu Moments')"
      ],
      "metadata": {
        "id": "Bn67u3Wlhnf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADA HOG"
      ],
      "metadata": {
        "id": "jkVs2f6chjC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_features_hog\n",
        "test = test_features_hog\n",
        "print('Processing - Ada Boost - HOG')\n",
        "print(train.shape, test.shape) \n",
        "\n",
        "classif = LogisticRegression(penalty='none', random_state=1)\n",
        "ada = AdaBoostClassifier(base_estimator=classif)\n",
        "ada.fit(train, train_labels)\n",
        "predicted = ada.predict(test)\n",
        "performance_evaluation(test, test_labels, predicted, 'Ada Boost - HOG')"
      ],
      "metadata": {
        "id": "yEWaL-ZGhjC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe2s2_WpVhDC"
      },
      "source": [
        "# 3. Discussão:\n",
        "\n",
        "* Análise e Discussão Crítica dos resultados\n",
        "* Expor casos de acerto e erros\n",
        "* OBS: Convença o avaliador sobre o seu entendimento sobre o que foi implementado, porque foi implementado, uma análise embasada dos resultados positivos e negativos, tal qual discutido em sala de aula\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WwwPz8dZVvKG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XEmw0MVfFOP-",
        "E5UTj_6jSht8",
        "aOd_o44gNQIi",
        "ggw6ges9Wozp",
        "qXAbQtcrZL6b",
        "OyrRmH14ZRGh",
        "fDNsip7EZUxt",
        "8Inz3fRw7-dO",
        "sm4AVTxJCUFu",
        "8UvXj0jJEICv",
        "qmYi09NIEKgs",
        "ssfox8QoZmTF",
        "v1TLByVWa30i",
        "r8HxhCr8a5Gw",
        "Rwk50hIta6sB",
        "nS8BWsgdbWLs",
        "lylUHziGbXna",
        "T3ZKN3-cbaCC",
        "C_AmZpy6fDYL",
        "I6TOTpb6fFWw",
        "Qt696hjchnf2",
        "qe2s2_WpVhDC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}